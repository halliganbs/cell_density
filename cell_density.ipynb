{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Density Notebook\n",
    "\n",
    "Ben Halligan\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Count number of cells in given area for microscope dataset\n",
    "\n",
    "## Images Parameters\n",
    "\n",
    "- Size: 2000 x 2000 x 1\n",
    "\n",
    "### TODO:\n",
    "\n",
    "- [x] Connect to google drive\n",
    "- [x] Load tiffs into dataframe\n",
    "- [x] Test train split\n",
    "- [x] General linear regression model\n",
    "- [ ] Train\n",
    "- [ ] Validate\n",
    "\n",
    "### Models\n",
    "\n",
    "#### VGG16 Model Description\n",
    "\n",
    "- Based on [this](https://github.com/LeanManager/PyTorch_Image_Classifier/blob/master/Image_Classifier_Project.ipynb) project\n",
    "- [VGG16 Model](https://neurohive.io/en/popular-networks/vgg16/)\n",
    "- Basic classification model for multiple classes\n",
    "\n",
    "#### Density Map CNN\n",
    "\n",
    "- Creates heat maps of where obejects are\n",
    "- Estimates how many objects are there\n",
    "- [Descripition](https://towardsdatascience.com/objects-counting-by-estimating-a-density-map-with-convolutional-neural-networks-c01086f3b3ec)\n",
    "- [Github](https://github.com/NeuroSYS-pl/objects_counting_dmap)\n",
    "- Going to either annotate data, **OR** make something to find cells for counting\n",
    "\n",
    "\n",
    "#### Other One implement later, maybe\n",
    "\n",
    "- [Link](https://papers.nips.cc/paper/2010/file/fe73f687e5bc5280214e0486b273a5f9-Paper.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import(\n",
    "    io, measure\n",
    ")\n",
    "\n",
    "# check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current Device: {device}\")\n",
    "\n",
    "# Google Auth\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.LocalWebserverAuth()\n",
    "\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "PATH = 'data/INS1_BF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6000', '4000', '2000', '10000', '8000', '0']\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(PATH)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data\n",
    "\n",
    "\n",
    "data = datasets.ImageFolder(root='data/INS1_BF', transform=transforms.ToTensor())\n",
    "print(data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 3, 2000, 2000])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Load data with data loader\n",
    "\n",
    "loader = DataLoader(data, batch_size= 64, shuffle=True)\n",
    "dataiter = iter(loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split\n",
    "train_size = int(0.8*len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
