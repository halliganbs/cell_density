{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Density Notebook\n",
    "\n",
    "Ben Halligan\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Count number of cells in given area for microscope dataset\n",
    "\n",
    "## Images Parameters\n",
    "\n",
    "- Size: 2000 x 2000 x 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- [x] Connect to google drive\n",
    "- [x] Load tiffs into dataframe\n",
    "- [x] Test train split\n",
    "- [x] General linear regression model\n",
    "- [ ] Train\n",
    "- [ ] Validate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import(\n",
    "    io, measure\n",
    ")\n",
    "\n",
    "# check for GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current Device: {device}\")\n",
    "\n",
    "# Google Auth\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.LocalWebserverAuth()\n",
    "\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "PATH = 'data/INS1_BF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '10000', '2000', '4000', '6000', '8000']\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(PATH)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "data = datasets.ImageFolder(root='data/INS1_BF', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with data loader\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(data, batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using VGG16 Image Model\n",
    "model_vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def conv_layer(in_channels: int, out_channels: int, \n",
    "               kernels: Tuple[int,int], stride: int=1):\n",
    "    \n",
    "    layer = nn.Sequential(\n",
    "         nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                     kernel_size=kernels, stride=stride, bias=False, \n",
    "                     padding=(kernels[0] //2, kernels[1] // 2)),\n",
    "        nn.BatchNorm2d(num_features=out_channels),\n",
    "        nn.ReLU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "#### VGG16 Model Description\n",
    "\n",
    "- Based on [this](https://github.com/LeanManager/PyTorch_Image_Classifier/blob/master/Image_Classifier_Project.ipynb) project\n",
    "- [VGG16 Model](https://neurohive.io/en/popular-networks/vgg16/)\n",
    "\n",
    "#### Density Map CNN\n",
    "\n",
    "- Creates heat maps of where obejects are\n",
    "- Estimates how many objects are there\n",
    "- [Descripition](https://towardsdatascience.com/objects-counting-by-estimating-a-density-map-with-convolutional-neural-networks-c01086f3b3ec)\n",
    "- [Github](https://github.com/NeuroSYS-pl/objects_counting_dmap)\n",
    "\n",
    "#### Other One implement later, maybe\n",
    "\n",
    "- [Link](https://papers.nips.cc/paper/2010/file/fe73f687e5bc5280214e0486b273a5f9-Paper.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCRN(nn.Module):\n",
    "    \n",
    "    def __init__(self, N: int=1, input_filters: int=1, ):\n",
    "        super(FCRN, self).__init__()\n",
    "        self.model= nn.Sequential(\n",
    "            # Downsampling\n",
    "            conv_layer(input_filters, 32, (32, 32)),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            conv_layer(32, 64, (32, 32)),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            conv_layer(64, 128,(32, 32)),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # fully connected cnn\n",
    "            conv_layer(128, 512, (32, 32)),\n",
    "            \n",
    "            # upsampling\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_layer(512, 128, (32, 32)),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_layer(128, 64, (32, 32)),\n",
    "            \n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_layer(64, 1, (32, 32))\n",
    "        )\n",
    "        \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return self.model(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcrn = FCRN(input_filters=1)\n",
    "\n",
    "# # Freeze pretrained model parameters to avoid backpropogating through them\n",
    "# for parameter in fcrn.parameters():\n",
    "#     parameter.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "# New classifier \n",
    "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
    "                                        ('relu', nn.ReLU()),\n",
    "                                        ('drop', nn.Dropout(p=0.5)),\n",
    "                                        ('fc2', nn.Linear(5000, 6)),\n",
    "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "\n",
    "# model.classifier = classifier\n",
    "fcrn.classifier = classifier\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(fcrn.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Train Split\n",
    "train_size = int(0.8*len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader):\n",
    "    \n",
    "    epochs = 2\n",
    "    steps = 0\n",
    "    print_every = 10\n",
    "    model.to('cuda')\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        \n",
    "        for images, labels in iter(train_loader):\n",
    "            steps +=1\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if steps % print_every == 0:\n",
    "                \n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                        validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
    "            \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs+1),\n",
    "                        \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                        \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
    "                        \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
    "            \n",
    "                running_loss = 0\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First: <class 'list'>, Second: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_loader)\n",
    "first = next(it)\n",
    "second =next(it)\n",
    "\n",
    "print(f' First: {type(first)}, Second: {type(second)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(fcrn, criterion, optimizer, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "\n",
    "def test_accuracy(model, test_loader):\n",
    "    \n",
    "    # Validate test set\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accuracy = 0\n",
    "        \n",
    "        for images, labels in iter(test_loader):\n",
    "            \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            \n",
    "            probabilities = torch.exp(output)\n",
    "            \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "            \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "            \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Load the checkpoint\n",
    "\n",
    "def save_checkpoint(model):\n",
    "    \n",
    "    model.class_to_idx = training_dataset.class_to_idx\n",
    "    \n",
    "    checkpoint = {'arch':\"vgg16\",\n",
    "                 'class_to_idx': model.class_to_idx,\n",
    "                 'model_state_dict':model.state_dict()\n",
    "                 }\n",
    "    torch.save(checkpoint, 'checkpoint.pth')\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    if checkpoint['arch'] == 'vgg16':\n",
    "        \n",
    "        model = models.vgg16(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            print('Architecture not recognized')\n",
    "        \n",
    "        model.class_to_idx = checkpoint['class_to_idx']\n",
    "        classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 5000)),\n",
    "                                            ('relu', nn.ReLU()),\n",
    "                                            ('drop', nn.Dropout(p=0.5)),\n",
    "                                            ('fc2', nn.Linear(5000, 102)),\n",
    "                                            ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
