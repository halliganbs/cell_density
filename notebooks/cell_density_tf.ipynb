{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Density - using Tensorflow\n",
    "\n",
    "### Counting number of cells within a given image\n",
    "\n",
    "A regression problem using image data\n",
    "\n",
    "Ben Halligan 2020/12/08\n",
    "\n",
    "- https://arxiv.org/pdf/1803.08450.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Num GPUs Available:  2\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# model using VGG16 to start\n",
    "from keras.applications import VGG16, InceptionResNetV2\n",
    "from tensorflow.keras import Input, layers, models\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dropout, Dense, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.metrics import Precision\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold # might not need\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import PIL\n",
    "import pathlib\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "data_path = 'data/edges/'\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(['/gpu:0','/gpu:1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 312 images belonging to 6 classes.\n",
      "Found 72 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (200, 200)\n",
    "batch_size = 16\n",
    "\n",
    "# datagenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "# train\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# test\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=img_size,\n",
    "    color_mode='grayscale',\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 200, 200, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 200, 200, 32)      800       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1280000)           0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                20480016  \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 20,481,273\n",
      "Trainable params: 20,480,841\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Input\n",
    "inputs = Input(shape=img_size+(1,))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization(1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "# regression end\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.build(new_input.shape)\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError(reduction='sum_over_batch_size', name='mean_squared_error')\n",
    "model.compile(optimizer='SGD',loss='mean_absolute_error',\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19/19 [==============================] - 8s 433ms/step - loss: 0.1698 - accuracy: 0.8333 - val_loss: 0.1683 - val_accuracy: 0.8333\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.1700 - accuracy: 0.8333 - val_loss: 0.1700 - val_accuracy: 0.8333\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 8s 421ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1717 - val_accuracy: 0.8333\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 8s 414ms/step - loss: 0.1702 - accuracy: 0.8333 - val_loss: 0.1678 - val_accuracy: 0.8333\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 8s 413ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1722 - val_accuracy: 0.8333\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.1700 - accuracy: 0.8333 - val_loss: 0.1683 - val_accuracy: 0.8333\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 8s 413ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1700 - val_accuracy: 0.8333\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1717 - val_accuracy: 0.8333\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 8s 413ms/step - loss: 0.1701 - accuracy: 0.8333 - val_loss: 0.1678 - val_accuracy: 0.8333\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 8s 414ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1722 - val_accuracy: 0.8333\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 8s 416ms/step - loss: 0.1702 - accuracy: 0.8333 - val_loss: 0.1683 - val_accuracy: 0.8333\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.1700 - accuracy: 0.8333 - val_loss: 0.1700 - val_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 8s 410ms/step - loss: 0.1700 - accuracy: 0.8333 - val_loss: 0.1717 - val_accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 8s 414ms/step - loss: 0.1702 - accuracy: 0.8333 - val_loss: 0.1678 - val_accuracy: 0.8333\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.1699 - accuracy: 0.8333 - val_loss: 0.1722 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch = train_gen.samples//batch_size,\n",
    "    validation_data = test_gen,\n",
    "    validation_steps = test_gen.samples//batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "prec = history.history['precision']\n",
    "val_prec = history.history['val_precision']\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, prec, label='Training Precision')\n",
    "plt.plot(epochs_range, val_prec, label='Validation Precision')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Precision')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
